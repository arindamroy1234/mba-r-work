************************************************************************
# Title: Module 6HE Logistic Regression
Course: MBA563
Term: Fall 2023
Mooc or HE?: HE
Module: 06
Author: Kim Mendoza and Jessen Hobson
************************************************************************

*********LOGIT*********************************************************
In class notebook
*********LOGIT*********************************************************



1.0 Load and summarize
# Initial loading of data, packages, and functions
```{r}
# RStudio Options
options(scipen = 1000) #Prevent display in scientific notation
# Run this reusable confusion matrix function (https://en.wikipedia.org/wiki/Confusion_matrix)
my_confusion_matrix <- function(cf_table) {
  true_positive <- cf_table[4]
  true_negative <- cf_table[1]
  false_positive <- cf_table[2]
  false_negative <- cf_table[3]
  accuracy <- (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)
  sensitivity_recall <- true_positive / (true_positive + false_negative) 
  specificity_selectivity <- true_negative / (true_negative + false_positive)
  precision <- true_positive / (true_positive + false_positive) 
  neg_pred_value <- true_negative/(true_negative + false_negative)
  print(cf_table)
  my_list <- list(sprintf("%1.0f = True Positive (TP), Hit", true_positive),
                  sprintf("%1.0f = True Negative (TN), Rejection", true_negative),
                  sprintf("%1.0f = False Positive (FP), Type 1 Error", false_positive),
                  sprintf("%1.0f = False Negative (FN), Type 2 Error", false_negative),
                  sprintf("%1.4f = Accuracy (TP+TN/(TP+TN+FP+FN))", accuracy), 
                  sprintf("%1.4f = Sensitivity, Recall, Hit Rate, True Positive Rate (How many positives did the model get right? TP/(TP+FN))", sensitivity_recall),
                  sprintf("%1.4f = Specificity, Selectivity, True Negative Rate (How many negatives did the model get right? TN/(TN+FP))", specificity_selectivity),
                  sprintf("%1.4f = Precision, Positive Predictive Value (How good are the model's positive predictions? TP/(TP+FP))", precision),
                  sprintf("%1.4f = Negative Predictive Value (How good are the model's negative predictions? TN/(TN+FN)", neg_pred_value)
  )
  return(my_list)
}
```

# Install and load packages (don't install twice)
```{r}
#install.packages('tidyverse')
library(tidyverse)

# Load data
df <- read_rds(r"(C:\Users\kimendoz\Documents\MBA 563\Module 6 Live Session\mod6HE_logit.rds)")

# Explore the data and discuss in PowerPoint
summary(df)
```
















































2.0 Run the Logistic Algorithm
# Prepare the data
```{r}
# Not for the model (for use later)
ColumnsNotUsed <- df %>% 
  select(store, week, high_med_rev, high_med_units, high_med_gpm)

# For use in the model
logit1 <- df %>% 
  select(high_med_gp, 
         size, region, promo_units_per, 
         altbev_units_per, confect_units_per, salty_units_per,
         velocityA_units_per, velocityB_units_per, velocityC_units_per, velocityD_units_per, velocityNEW_units_per)

```










































# Partition the data into testing and training datasets

See power point for intuition

```{r}
#install.packages('caret') (don't install twice)
library(caret)
set.seed(42) 
partition <- caret::createDataPartition(y=logit1$high_med_gp, p=.75, list=FALSE) #gives matrix of row numbers
data_train <- logit1[partition, ] #keeps the rows indicated in `partition` and all columns from `logit1`
data_test <- logit1[-partition, ] #keeps the rows not indicated in `partition` and all columns from `logit1`
```


































# Train the multivariate model - these are the instructions part of machine learning
```{r}
model_train <- glm(high_med_gp ~ ., family=binomial, data=data_train)
summary(model_train)
```

Questions to discuss:
1) What do the coefficients mean here? Specifically, explain the meaning of the coefficient on “promo_units_per”. 
Don't get too technical, just say whether it helps or hurts profitability.

2) What does the p-value mean?






































# Predict the response variable on the test data using the training data
```{r}
predict_test <- predict(model_train, newdata=data_test, type='response')
```






























# Form table to look at the accuracy of the model
```{r}
table2 <- table(predict_test>.5, data_test$high_med_gp) #prediction on left and truth on top
my_confusion_matrix(table2)
```

Breakout!




































3.0 Use the predictions above to help the business
# Put the data back together for future use
```{r}
# Put the prediction back into the test data
data_test$prediction <- predict_test

# Create a variable that shows if the prediction was correct 
# (We have to do the classification--in `round(prediction)`--since logistic regression gives us a probability)
data_test <- data_test %>% 
  mutate(correct_prediction = if_else(round(prediction) == high_med_gp, 'correct', 'WRONG!'))

# Add back the original data
temp1 <- ColumnsNotUsed[-partition, ]
full_test <- bind_cols(temp1, data_test)

# For viewing in class
full_test <- full_test %>% 
  select(store, week, high_med_gp, prediction, correct_prediction, 
         size, region, promo_units_per, salty_units_per)
slice_sample(full_test, n=10)
```


